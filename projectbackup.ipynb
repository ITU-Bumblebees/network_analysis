{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Project\n",
    "\n",
    "#### For this project we will start by importing the necessary libraries \n",
    "#!pip install pyvis\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import networkx as nx\n",
    "from networkx.algorithms import bipartite \n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as colors\n",
    "import matplotlib.cm as cmx\n",
    "from matplotlib.colors import ListedColormap\n",
    "import seaborn as sns\n",
    "from pyvis.network import Network \n",
    "#pip install decorator==4.3\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "##### Now we will import the csv files to start working with the data\n",
    "#First we need to get the data from the csv file, made into a data frame\n",
    "attributes= pd.read_csv('Data/nodeattribute.csv', delimiter=';')\n",
    "edgelist= pd.read_csv('Data/edgelist.csv',delimiter=';')\n",
    "g_attributes= attributes[attributes['0']=='gene']\n",
    "d_attributes = attributes[attributes['0']=='disease']\n",
    "\n",
    "\n",
    "#We need to convert the data frame into a dictionary to use the set_node_attributes \n",
    "nodes_attr = attributes.set_index('Id').to_dict(orient='index')\n",
    "g_nodes_attr = g_attributes.set_index('Id').to_dict(orient='index')\n",
    "d_nodes_attr= d_attributes.set_index('Id').to_dict(orient='index')\n",
    "\n",
    "\n",
    "#Made it into a list\n",
    "g_nodes= g_attributes['Id'].to_list()\n",
    "d_nodes=d_attributes['Id'].to_list()\n",
    "edges= edgelist.values.tolist()\n",
    "\n",
    "\n",
    "G = nx.Graph()\n",
    "G.add_nodes_from(g_nodes, bipartite=0)\n",
    "G.add_nodes_from(d_nodes, bipartite=1)\n",
    "nx.set_node_attributes(G, nodes_attr)\n",
    "G.add_edges_from(edges)\n",
    "\n",
    "print(G.nodes[1285]['0'])\n",
    "\n",
    "#bottom_nodes, top_nodes = bipartite.sets(G)\n",
    "#Checking that the code worked properly\n",
    "G.nodes()\n",
    "#G.edges()\n",
    "#G.nodes[55][\"Label\"]\n",
    "#nodes_attr\"\"\"\n",
    "\n",
    "G.nodes[117]['bipartite']\n",
    "In order to start working with the graph we need to make sure it is connected \n",
    "print(nx.is_connected(G))\n",
    "print(nx.is_bipartite(G))\n",
    "\n",
    "### Project description\n",
    "1. Basic network description of your data (what type of network it is, what does it represent, is it real or synthetically generated, etc). In practice, the result of project phase #1 (finding data).\n",
    "It is a unipartite, undirected and unweighted network that describes the associations between human diseases and human genes, as extracted from the Morbid Map (MM) of the Online Mendelian Inheritance in Man (OMIM) in 2005.\n",
    "\n",
    "Source : https://github.com/gephi/gephi/wiki/Datasets\n",
    "\n",
    "2. Basic network statistics of your data (number of nodes, edges, clustering, degree distribution, etc). In practice, the result of project phase #2 (exploratory data analysis)\n",
    "#Graph properties \n",
    "\"\"\"\n",
    "nx.is_directed(G)\n",
    "nx.is_bipartite(G)\n",
    "ns.is_weighted(G)\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "#the number of nodes and egdes\n",
    "num_nodes = len(G.nodes())\n",
    "num_genes= len(g_nodes)\n",
    "num_diseases= len(d_nodes) \n",
    "num_edges= len(G.edges())\n",
    "\n",
    "#Printing the num of nodes and edges\n",
    "print(f'The number of nodes that are genes is: {num_genes}\\nThe number of nodes that are diseases is: {num_diseases}\\n---\\nThe total number of nodes is: {num_nodes} ')\n",
    "print(f'\\n---\\nThe number of edges is: {num_edges}')\n",
    "\n",
    "\n",
    "def make_df(column2, function, graph):\n",
    "    df = pd.DataFrame(list(function(graph).items()), columns=['Id', column2])\n",
    "    df.set_index('Id', inplace=True)\n",
    "\n",
    "    return df\n",
    "\n",
    "closeness = make_df('closeness', nx.closeness_centrality, G)\n",
    "degree_centrality = make_df('degree', nx.degree_centrality, G)\n",
    "\n",
    "df= degree_centrality.join(closeness, on='Id')\n",
    "#density \n",
    "density = nx.density(G)\n",
    "\n",
    "\n",
    "#### Clustering\n",
    "#global clustering coefficient\n",
    "print(nx.transitivity(G))\n",
    "\n",
    "#average clustering coefficient\n",
    "print(nx.average_clustering(G))\n",
    "\n",
    "#local clustering coefficient\n",
    "#print(nx.clustering(G))\n",
    "#### Degree Distribution\n",
    "degree_freq = nx.degree_histogram(G)\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "sns.set_theme(style='whitegrid')\n",
    "plt.yscale('log')\n",
    "ax.hist(degree_freq);\n",
    "ax.set_xlabel('Degree');\n",
    "ax.set_ylabel('Frequency');\n",
    "ax.set_title('Degree Distribution');\n",
    "degree_freq = [x/sum(degree_freq) for x in degree_freq] #normalized degree frequency\n",
    "degree_range = range(len(degree_freq)) \n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "ax.set_title('Degree Distribution');\n",
    "ax.set_xlabel('Degree');\n",
    "ax.set_ylabel('Fraction of Nodes with Degree >= k');\n",
    "\n",
    "deg = [0]*len(degree_freq)\n",
    "sum_of_all = sum(degree_freq)\n",
    "for i in range(len(deg)):\n",
    "    for j in range(i,len(deg)):\n",
    "        deg[i] += degree_freq[j]\n",
    "    deg[i] = deg[i]/sum_of_all\n",
    "\n",
    "ax.loglog(degree_range, deg);\n",
    "\n",
    "\n",
    "### Graph representation\n",
    "print(nx.is_directed(G))\n",
    "print(nx.is_bipartite(G))\n",
    "print(nx.is_weighted(G))\n",
    "label= nx.get_node_attributes(G,'Label')\n",
    "classification = nx.get_node_attributes(G,'0')\n",
    "typeofclassification= nx.get_node_attributes(G,'1')\n",
    "\n",
    "#classification[1329]\n",
    "#typeofclassification[1329]\n",
    "\n",
    "#G.nodes()\n",
    "#nodes_attr\n",
    "def draw_graph(G):   \n",
    "    fig, ax = plt.subplots(figsize=(150,100))\n",
    "    color_map = ['#7c0a02' if G.nodes[node]['bipartite'] == 0 else '#f4c2c2' for node in G]\n",
    "\n",
    "    nx.draw(G, node_color = color_map, with_labels = True)\n",
    "\n",
    "    plt.title('Graph representation', fontsize = 100);\n",
    "# Visualizing the network using Pyvis\n",
    "def make_interactive(attributes, edges):\n",
    "    trial = attributes.set_index('Id')\n",
    "    n = attributes['Id'].to_list()\n",
    "    t= attributes['Label'].to_list()\n",
    "    l= attributes['0'].to_list()\n",
    "    l1 = attributes['1'].to_list()\n",
    "    attributes['color'] = np.where(attributes['0']== 'disease', '#7c0a02' , '#f4c2c2')\n",
    "    c = attributes['color'].to_list()\n",
    "\n",
    "\n",
    "    net = Network('100vh', '100vw')\n",
    "\n",
    "    net.add_nodes(n, title=l, label=t, color=c)\n",
    "    net.add_edges(edges)\n",
    "    net.show('jk.html')\n",
    "draw_graph(G)\n",
    "Gp = bipartite.weighted_projected_graph(G, d_nodes)\n",
    "draw_graph(Gp)\n",
    "\n",
    "\n",
    "t= pd.DataFrame(list(Gp.edges(data=True)), columns=['src', 'trg', 'Weight'])\n",
    "#list(Gp.nodes(data=True))\n",
    "t['Weight'] = [int(k['weight']) for k in t['Weight']]\n",
    "\n",
    "t.to_csv(sep='\\t', path_or_buf='Data/new_file',header=True)\n",
    "\n",
    "\n",
    "# the input needs to be a file separated by tabs, can be generated from pd dataframe\n",
    "import backboning\n",
    "table, nnodes, nnedges = backboning.read(\"Data/new_file\", \"Weight\", triangular_input=True)\n",
    "nc_table = backboning.noise_corrected(table)\n",
    "nc_backbone = backboning.thresholding(nc_table, 2)\n",
    "nc_backbone\n",
    "list(Gp.nodes(data=True))\n",
    "temp = d_attributes\n",
    "categories = np.unique(d_attributes['1'])\n",
    "temp['1'] = pd.Categorical(temp['1'])\n",
    "\n",
    "pos = nx.spring_layout(Gp)\n",
    "colorlegend = {a:b  for b,a in enumerate(categories)}\n",
    "\n",
    "colors = ['#800000', '#FF0000', '#FF7F50', '#FF8C00', '#FFD700',\n",
    " '#EEE8AA', '#BDB76B', '#808000', '#7CFC00', '#006400', \n",
    " '#98FB98', '#20B2AA', '#2F4F4F', '#00FFFF', '#AFEEEE',\n",
    " '#6495ED','#191970','#8A2BE2','#4B0082','#DDA0DD',\n",
    " '#A0522D','#DEB887']\n",
    "colors = ListedColormap(colors)\n",
    "\n",
    "val_map = temp['1'].cat.codes.to_dict()\n",
    "values = [val_map.get(node, 0) for node in Gp.nodes()]\n",
    "cNorm  = colors.Normalize(vmin=0, vmax=max(values))\n",
    "scalarMap = cmx.ScalarMappable(norm=cNorm, cmap=colors)\n",
    "\n",
    "f = plt.figure(1, figsize=(30, 30))\n",
    "ax = f.add_subplot(1,1,1)\n",
    "for label in colorlegend:\n",
    "    ax.plot([0],[0],color=scalarMap.to_rgba(colorlegend[label]),label=label)\n",
    "\n",
    "nx.draw(Gp, pos,  with_labels = True, node_color = temp['1'].cat.codes, cmap = colors, vmin = 0, vmax = max(values))\n",
    "\n",
    "plt.legend();\n",
    "\n",
    "## Assortativity of the projected network\n",
    "We use the function $trace(M)-sum(M^2))/(1-sum(M^2))$, where M is the joint probability distribution (mixing matrix) of the specified attribute.\n",
    "or in easier to understand math\n",
    "$$r = \\dfrac{\\sum_ie_{ii} - \\sum_ia_ib_i}{1-\\sum_ia_ib_i}$$\n",
    "nx.attribute_assortativity_coefficient(Gp, \"1\")\n",
    "A score of 0.44 means we can say it is moderately assortative since it is above 0 on a [-1;1] scale. \n",
    "## Clustering\n",
    "#global clustering coefficient\n",
    "print(nx.transitivity(Gp))\n",
    "\n",
    "#average clustering coefficient\n",
    "print(nx.average_clustering(Gp))\n",
    "\n",
    "#local clustering coefficient\n",
    "print(nx.clustering(Gp))\n",
    "from collections import defaultdict\n",
    "\n",
    "def homophily_per_group(graph):\n",
    "    types_diseases = defaultdict(list)\n",
    "    for node in graph.nodes():\n",
    "        group = graph.nodes[node]['1']\n",
    "        count = 0 \n",
    "        num_neighbors= len(list(graph.neighbors(node)))\n",
    "        for n_node in list(graph.neighbors(node)):\n",
    "            n_group= graph.nodes[n_node]['1']\n",
    "            \n",
    "            if group == n_group: \n",
    "                count +=1\n",
    "                \n",
    "        types_diseases[group].append(count/num_neighbors)\n",
    "        \n",
    "    for key,val in types_diseases.items():\n",
    "        value = sum(val) / len(val)\n",
    "        types_diseases.update({key: value})\n",
    "\n",
    "\n",
    "    return types_diseases\n",
    "\n",
    "\n",
    "#homophily_per_group(bipar_weighted).items()\n",
    "\n",
    "\n",
    "\n",
    "def list_degrees(graph): \n",
    "    l = list(graph.degree())\n",
    "    l_sorted= sorted(l, key=lambda t: t[1], reverse=True)\n",
    "    \n",
    "    return l_sorted\n",
    "\n",
    "degrees = pd.DataFrame(list_degrees(bipar_weighted), columns=['NodeID', 'Degree'])\n",
    "\n",
    "plt.figure(1, figsize=(30, 30))\n",
    "sns.histplot(data=degrees,  x='Degree')\n",
    "plt.title('Degree Distribution', fontsize=50)\n",
    "plt.xlabel('Nodes', size=20)\n",
    "plt.ylabel('Degrees', size=20)\n",
    "degrees.head(200)\n",
    "bipar_weighted.nodes[45]['1']\n",
    "homophily_per_group(bipar_weighted)\n",
    "list(bipar_weighted.neighbors(68))\n",
    "def group(graph):\n",
    "    dict_nodes=defaultdict(list)\n",
    "    num_nodes = defaultdict(int)\n",
    "    for node in graph.nodes():\n",
    "        group = graph.nodes[node]['1']\n",
    "        dict_nodes[group].append(node)\n",
    "        num_nodes[group] += 1\n",
    "    \n",
    "    return dict_nodes, num_diseases\n",
    "\n",
    "\n",
    "group(bipar_weighted)\n",
    "\n",
    "#barplot of nodes above th\n",
    "#th at least 5% of the data -> 26\n",
    "#68, 187, 902, 1307\n",
    "\n",
    "bipar_weighted.nodes[1307]"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
